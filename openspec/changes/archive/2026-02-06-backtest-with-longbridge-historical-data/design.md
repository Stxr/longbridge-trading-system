## Context

当前交易系统已具备基础的回测框架，但缺乏高效获取和管理长桥（Longbridge）高精度历史数据的能力。为了支持高频或精细化策略的回测，需要实现一套能够同步并存储长桥最高精度（1分钟线）数据的机制。

## Goals / Non-Goals

**Goals:**
- **最高精度支持**：支持长桥提供的 1 分钟精度（`Period.Min_1`）K 线数据的拉取与存储。
- **本地持久化**：使用 SQLite 存储数据，确保回测时无需反复请求 API。
- **增量同步**：实现智能同步逻辑，能够自动识别本地缺失的数据范围并进行补全。
- **高性能查询**：优化数据库索引，确保回测引擎加载海量 K 线数据时的响应速度。

**Non-Goals:**
- 不支持 Tick 级数据存储（长桥 OpenAPI 对历史 Tick 的获取有更高限制或不同接口，本阶段聚焦 K 线）。
- 不提供复杂的图形化数据管理界面。

## Decisions

### 1. 存储选型：SQLite + Drizzle ORM (或原生 SQL)
- **决策**：使用 SQLite 作为本地数据库。
- **理由**：回测数据属于本地私有数据，SQLite 无需安装服务端，文件即数据库，方便迁移和备份。其性能足以应付百万级 K 线数据的随机读写。
- **替代方案**：PostgreSQL (运维成本高，对单机回测过度设计)。

### 2. 数据表结构设计
- **表名**：`klines`
- **字段**：
  - `symbol` (TEXT): 股票代码（如 "700.HK"）
  - `period` (TEXT): 周期（"1m", "5m", "1d" 等）
  - `timestamp` (INTEGER): Unix 时间戳（毫秒），作为主键或索引。
  - `open`, `high`, `low`, `close`, `volume`, `turnover` (REAL/NUMERIC): 价格与成交数据。
- **索引**：`(symbol, period, timestamp)` 复合唯一索引，用于加速时间区间查询并防止数据重复。

### 3. 同步逻辑：高精度递归回溯
- **决策**：使用 `historyCandlesticksByOffset` 接口配合 `NaiveDatetime`。
- **逻辑**：
  - 分页拉取：每次拉取 1000 条，获取该批次最早时间戳。
  - 精确回溯：以下一秒作为新请求的结束时间，确保分钟线级别无缝衔接。
  - 增量合并：使用 `ON CONFLICT` 逻辑，支持多次运行自动合并数据。

### 4. 存储优化
- **决策**：分批插入 (Chunking)。
- **理由**：规避 SQLite 对复合 SELECT 语句中 term 数量（500个）的限制，提升大批量同步时的稳定性。

## Risks / Trade-offs

- **[Risk] 存储空间占用** → **Mitigation**: 1 分钟线数据量较大，单只股票一年约 6-10 万条数据。将提供清理旧数据或压缩数据库的脚本。
- **[Risk] 复权问题** → **Mitigation**: 长桥历史数据支持调整类型（AdjustType）。同步时默认存储“前复权”数据，若需变更复权方式，需清空本地对应 symbol 的缓存。
- **[Risk] API 频率限制导致同步慢** → **Mitigation**: 实现断点续传功能，即使同步中断，下次运行也能从上次位置继续。
